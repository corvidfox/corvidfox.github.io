[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Morri",
    "section": "",
    "text": "Hi — I’m Morri, a data scientist with a clinical background, an MPH in progress, and a serious love of health data. I work at the intersection of epidemiology, bioinformatics, and analytics, building tools that make large, messy datasets more useful for research and public health. I’m especially excited by omics, reproducibility, and clever ways to reduce human effort without sacrificing rigor.\nBefore pivoting to data science, I spent over a decade as a nurse and educator — so I know my way around both a CRRT machine and a good data pipeline. My projects range from fuzzy-matching patient records across data sets, to meta-analyzing EWAS studies, to modeling viral phylogenies for vaccine strain selection.\nI care deeply about clarity, collaboration, and doing science that’s useful. I’d love to work on research teams, data-heavy health projects, or anything that needs solid analysis and a thoughtful partner. (Also: the dog’s name is Lucy. She does not code.)\n\n\n\n\nMPH in Epidemiology, In Progress (Est. December 2025)\nUniversity of Texas Health Sciences Center, School of Public Health (Houston, TX, USA)\nCertificate: Genomics & Bioinformatics\nCertificate: Data Science\nThesis: Epigenome-Wide Associations of Factor VIII and Von Willebrand Factor Levels (In Progress, Meta-Analysis, de Vries Lab)\nBSc in Nursing, 2019\nUniversity of Texas at Arlington (Arlington, TX, USA)\nBSc in Biology, 2013\nUniversity of Texas at Dallas (Richardson, TX, USA)  Minor: Sociology\n\n\n\n\n\n\nUTHealth Sciences Center, School of Public Health (Houston, TX, USA)\n\nPI: Dr. M. Brad Cannell\nContributed to public health research projects (DETECT, DETECT-RPC, Link2Care), supporting the full data lifecycle — from collection and cleaning to analysis and reporting.\nDeveloped and implemented probabilistic fuzzy-matching techniques using the fastLink R package to link subject data across datasets lacking common identifiers.\nDrafted statistical analysis plans, IRB protocols, informed consent forms, and conducted statistical analyses in R.\n\n\n\n\nTravel Nurse Across America, USA\n\nRapidly deployed to hospitals nationwide, delivering expert-level critical care in ICU and ED settings, managing complex cases across multiple specialties.\nLed interdisciplinary teams, acted as Charge Nurse and educator, and routinely utilized advanced technologies (e.g. ECMO, IABP, CRRT, Impella, and Blakemore/Compass, etc.)\n\n\n\n\nRochester General Hospital, Rochester, NY, USA\n\n\n\nCity of Plano, Plano, TX, USA"
  },
  {
    "objectID": "about.html#bio",
    "href": "about.html#bio",
    "title": "About Morri",
    "section": "",
    "text": "Hi — I’m Morri, a data scientist with a clinical background, an MPH in progress, and a serious love of health data. I work at the intersection of epidemiology, bioinformatics, and analytics, building tools that make large, messy datasets more useful for research and public health. I’m especially excited by omics, reproducibility, and clever ways to reduce human effort without sacrificing rigor.\nBefore pivoting to data science, I spent over a decade as a nurse and educator — so I know my way around both a CRRT machine and a good data pipeline. My projects range from fuzzy-matching patient records across data sets, to meta-analyzing EWAS studies, to modeling viral phylogenies for vaccine strain selection.\nI care deeply about clarity, collaboration, and doing science that’s useful. I’d love to work on research teams, data-heavy health projects, or anything that needs solid analysis and a thoughtful partner. (Also: the dog’s name is Lucy. She does not code.)"
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About Morri",
    "section": "",
    "text": "MPH in Epidemiology, In Progress (Est. December 2025)\nUniversity of Texas Health Sciences Center, School of Public Health (Houston, TX, USA)\nCertificate: Genomics & Bioinformatics\nCertificate: Data Science\nThesis: Epigenome-Wide Associations of Factor VIII and Von Willebrand Factor Levels (In Progress, Meta-Analysis, de Vries Lab)\nBSc in Nursing, 2019\nUniversity of Texas at Arlington (Arlington, TX, USA)\nBSc in Biology, 2013\nUniversity of Texas at Dallas (Richardson, TX, USA)  Minor: Sociology"
  },
  {
    "objectID": "about.html#work-experience",
    "href": "about.html#work-experience",
    "title": "About Morri",
    "section": "",
    "text": "UTHealth Sciences Center, School of Public Health (Houston, TX, USA)\n\nPI: Dr. M. Brad Cannell\nContributed to public health research projects (DETECT, DETECT-RPC, Link2Care), supporting the full data lifecycle — from collection and cleaning to analysis and reporting.\nDeveloped and implemented probabilistic fuzzy-matching techniques using the fastLink R package to link subject data across datasets lacking common identifiers.\nDrafted statistical analysis plans, IRB protocols, informed consent forms, and conducted statistical analyses in R.\n\n\n\n\nTravel Nurse Across America, USA\n\nRapidly deployed to hospitals nationwide, delivering expert-level critical care in ICU and ED settings, managing complex cases across multiple specialties.\nLed interdisciplinary teams, acted as Charge Nurse and educator, and routinely utilized advanced technologies (e.g. ECMO, IABP, CRRT, Impella, and Blakemore/Compass, etc.)\n\n\n\n\nRochester General Hospital, Rochester, NY, USA\n\n\n\nCity of Plano, Plano, TX, USA"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About Morri",
    "section": "",
    "text": "Hi — I’m Morri, a data scientist with a clinical background, an MPH in progress, and a serious love of health data. I work at the intersection of epidemiology, bioinformatics, and analytics, building tools that make large, messy datasets more useful for research and public health. I’m mainly excited by omics, reproducibility, and clever ways to reduce human effort without sacrificing rigor.\nBefore pivoting to data science, I was a critical care nurse and educator — so I know my way around both a CRRT machine and a good data pipeline. My projects range from fuzzy-matching patient records across data sets, to meta-analyzing EWAS studies, to modeling viral phylogenies for vaccine strain selection.\nI care deeply about clarity, collaboration, and doing science that’s useful. I’d love to work on research teams, data-heavy health projects, or anything that needs solid analysis and a thoughtful partner.\n\n\n\n\nMPH in Epidemiology, In Progress (Est. December 2025)\nUniversity of Texas Health Sciences Center, School of Public Health (Houston, TX, USA)\nCertificate: Genomics & Bioinformatics\nCertificate: Data Science\nThesis: Epigenome-Wide Associations of Factor VIII and Von Willebrand Factor Levels (In Progress, Meta-Analysis, de Vries Lab)\nBSc in Nursing, 2019\nUniversity of Texas at Arlington (Arlington, TX, USA)\nBSc in Biology, 2013\nUniversity of Texas at Dallas (Richardson, TX, USA)  Minor: Sociology\n\n\n\n\n\nGraduate Research Assistant, February 2023 - Present\nUTHealth Sciences Center, School of Public Health (Houston, TX, USA)\n\n\nPI: Dr. M. Brad Cannell\nContributed to public health research projects (DETECT, DETECT-RPC, Link2Care), supporting the full data lifecycle — from collection and cleaning to analysis and reporting.\nDeveloped and implemented probabilistic fuzzy-matching techniques using the fastLink R package to link subject data across datasets lacking common identifiers.\nDrafted statistical analysis plans, IRB protocols, informed consent forms, and conducted statistical analyses in R.\n\nCritical Care Travel Nurse, March 2021 - December 2022\nTravel Nurse Across America (USA)\n\n\nRapidly deployed to hospitals nationwide, delivering expert-level critical care in ICU and ED settings, managing complex cases across multiple specialties.\nLed interdisciplinary teams, acted as Charge Nurse and educator, and routinely utilized advanced technologies (e.g. ECMO, IABP, CRRT, Impella, and Blakemore/Compass, etc.)\n\nRegistered Nurse (Residency), March 2020 - March 2021\nRochester General Hospital (Rochester, NY, USA)\nPublic Safety Communications Specialist, February 2018 - February 2020\nCity of Plano (Plano, TX, USA)"
  },
  {
    "objectID": "index.html#bio",
    "href": "index.html#bio",
    "title": "About Morri",
    "section": "",
    "text": "Hi — I’m Morri, a data scientist with a clinical background, an MPH in progress, and a serious love of health data. I work at the intersection of epidemiology, bioinformatics, and analytics, building tools that make large, messy datasets more useful for research and public health. I’m mainly excited by omics, reproducibility, and clever ways to reduce human effort without sacrificing rigor.\nBefore pivoting to data science, I was a critical care nurse and educator — so I know my way around both a CRRT machine and a good data pipeline. My projects range from fuzzy-matching patient records across data sets, to meta-analyzing EWAS studies, to modeling viral phylogenies for vaccine strain selection.\nI care deeply about clarity, collaboration, and doing science that’s useful. I’d love to work on research teams, data-heavy health projects, or anything that needs solid analysis and a thoughtful partner."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "About Morri",
    "section": "",
    "text": "MPH in Epidemiology, In Progress (Est. December 2025)\nUniversity of Texas Health Sciences Center, School of Public Health (Houston, TX, USA)\nCertificate: Genomics & Bioinformatics\nCertificate: Data Science\nThesis: Epigenome-Wide Associations of Factor VIII and Von Willebrand Factor Levels (In Progress, Meta-Analysis, de Vries Lab)\nBSc in Nursing, 2019\nUniversity of Texas at Arlington (Arlington, TX, USA)\nBSc in Biology, 2013\nUniversity of Texas at Dallas (Richardson, TX, USA)  Minor: Sociology"
  },
  {
    "objectID": "index.html#work-experience",
    "href": "index.html#work-experience",
    "title": "About Morri",
    "section": "",
    "text": "Graduate Research Assistant, February 2023 - Present\nUTHealth Sciences Center, School of Public Health (Houston, TX, USA)\n\n\nPI: Dr. M. Brad Cannell\nContributed to public health research projects (DETECT, DETECT-RPC, Link2Care), supporting the full data lifecycle — from collection and cleaning to analysis and reporting.\nDeveloped and implemented probabilistic fuzzy-matching techniques using the fastLink R package to link subject data across datasets lacking common identifiers.\nDrafted statistical analysis plans, IRB protocols, informed consent forms, and conducted statistical analyses in R.\n\nCritical Care Travel Nurse, March 2021 - December 2022\nTravel Nurse Across America (USA)\n\n\nRapidly deployed to hospitals nationwide, delivering expert-level critical care in ICU and ED settings, managing complex cases across multiple specialties.\nLed interdisciplinary teams, acted as Charge Nurse and educator, and routinely utilized advanced technologies (e.g. ECMO, IABP, CRRT, Impella, and Blakemore/Compass, etc.)\n\nRegistered Nurse (Residency), March 2020 - March 2021\nRochester General Hospital (Rochester, NY, USA)\nPublic Safety Communications Specialist, February 2018 - February 2020\nCity of Plano (Plano, TX, USA)"
  },
  {
    "objectID": "projects/draft.html",
    "href": "projects/draft.html",
    "title": "R & SQL-Driven Business Intelligence Dashboard (Chinook ‘Digital Music Store’)",
    "section": "",
    "text": "Goal: Build a BI dashboard for a fictional digital media business.\nFocus: Revenue insights, customer analysis, business performance.\nWhy it matters: Business stakeholders need quick, clear access to KPIs.\n\n\n\nThe following tools were used to merge, analyze, and present the data:\n\n\n\nTool\nPurpose\n\n\n\n\nSQL\nData transformation and KPIs\n\n\nDuckDB\nLightweight, embedded relational database\n\n\nR + Shiny\nDashboard development (R-based)\n\n\nPython + Dash\nDashboard development (Python-based)\n\n\n\nThe project demonstrates dashboard development using both R (Shiny) and Python (Dash) to showcase flexibility across ecosystems.\n[NOTE TO SELF - DELETE ONCE REVISED: This is a work in progress. I plan to make a dashboard with R and one with Python, just to show I can do both. I will update this to reflect the final project once it’s done.]\n\nRPython\n\n\n\n\n\nr\n\nlibrary(duckdb)\nlibrary(dplyr)\nlibrary(DBI)\nlibrary(plotly)\nlibrary(countrycode)\n\n\n\n\n\n\n\npython\n\nimport duckdb\nimport pandas as pd\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport pycountry\n\n\n\n\n\n\n\n\nThis project is designed to help answer the following business questions:\n\nWhere is revenue coming from geographically?\nWhat genres or artists generate the most income?\nHow many customers are repeat buyers?\nHow do sales trends evolve over time?"
  },
  {
    "objectID": "projects/draft.html#technology-stack",
    "href": "projects/draft.html#technology-stack",
    "title": "R & SQL-Driven Business Intelligence Dashboard (Chinook ‘Digital Music Store’)",
    "section": "",
    "text": "The following tools were used to merge, analyze, and present the data:\n\n\n\nTool\nPurpose\n\n\n\n\nSQL\nData transformation and KPIs\n\n\nDuckDB\nLightweight, embedded relational database\n\n\nR + Shiny\nDashboard development (R-based)\n\n\nPython + Dash\nDashboard development (Python-based)\n\n\n\nThe project demonstrates dashboard development using both R (Shiny) and Python (Dash) to showcase flexibility across ecosystems.\n[NOTE TO SELF - DELETE ONCE REVISED: This is a work in progress. I plan to make a dashboard with R and one with Python, just to show I can do both. I will update this to reflect the final project once it’s done.]\n\nRPython\n\n\n\n\n\nr\n\nlibrary(duckdb)\nlibrary(dplyr)\nlibrary(DBI)\nlibrary(plotly)\nlibrary(countrycode)\n\n\n\n\n\n\n\npython\n\nimport duckdb\nimport pandas as pd\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport pycountry"
  },
  {
    "objectID": "projects/draft.html#business-questions",
    "href": "projects/draft.html#business-questions",
    "title": "R & SQL-Driven Business Intelligence Dashboard (Chinook ‘Digital Music Store’)",
    "section": "",
    "text": "This project is designed to help answer the following business questions:\n\nWhere is revenue coming from geographically?\nWhat genres or artists generate the most income?\nHow many customers are repeat buyers?\nHow do sales trends evolve over time?"
  },
  {
    "objectID": "projects/draft.html#question-1-where-is-revenue-coming-from-geographically",
    "href": "projects/draft.html#question-1-where-is-revenue-coming-from-geographically",
    "title": "R & SQL-Driven Business Intelligence Dashboard (Chinook ‘Digital Music Store’)",
    "section": "Question 1: Where is revenue coming from geographically?",
    "text": "Question 1: Where is revenue coming from geographically?\nAnalysis of geographic revenue began with the country recorded in the Invoice table. This geographic value reflected where purchases were billed, which is often used as the default location reference for financial reporting.\n\n\n\nsql\n\n-- Revenue by Country (Billing)\nSELECT \n    i.BillingCountry, \n    SUM(i.Total) AS TotalRevenue,\n    ROUND(SUM(i.Total)*100.0 / (SELECT SUM(Total) from Invoice), 2) AS PercentGlobalRevenue,\n    COUNT(DISTINCT c.CustomerId) AS NumCustomers,\n    ROUND(SUM(i.Total) / COUNT(DISTINCT c.CustomerId), 2) AS RevenuePerCustomer\nFROM Customer c\nJOIN Invoice i on c.CustomerId == i.CustomerId\nGROUP BY i.BillingCountry\n-- Sort Revenue (Highest to Lowest)\nORDER BY TotalRevenue DESC;\n\n\n\nDisplaying records 1 - 10\n\n\n\n\n\n\n\n\n\nBillingCountry\nTotalRevenue\nPercentGlobalRevenue\nNumCustomers\nRevenuePerCustomer\n\n\n\n\nUSA\n523.06\n22.46\n13\n40.24\n\n\nCanada\n303.96\n13.05\n8\n37.99\n\n\nFrance\n195.10\n8.38\n5\n39.02\n\n\nBrazil\n190.10\n8.16\n5\n38.02\n\n\nGermany\n156.48\n6.72\n4\n39.12\n\n\nUnited Kingdom\n112.86\n4.85\n3\n37.62\n\n\nCzech Republic\n90.24\n3.88\n2\n45.12\n\n\nPortugal\n77.24\n3.32\n2\n38.62\n\n\nIndia\n75.26\n3.23\n2\n37.63\n\n\nChile\n46.62\n2.00\n1\n46.62\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\nThe customer base is geographically uneven:\n\nThe United States alone accounts for a quarter of global revenue (22.46%).\nThe top five countries (USA, Canada, France, Brazil, Germany) contribute over half (58.77%) of global revenue.\n\nOpportunity: Expanding to underrepresented regions could be a growth opportunity - if demand can be identified and activated.\n\n\n\n\n\n\n\n\nInsights\n\n\n\nThere are different customer behavior patterns in each country.\n\nNone of the top revenue-generating countries appear in the top five for revenue-per-customer (Chile, Hungary, Ireland, Czech Republic, Austria).\nHigh total revenue countries likely have large but casual user bases.\nHigh per-customer revenue countries likely reflect smaller but more valuable audiences..\n\nOpportunities: - High total revenue countries are ideal for retention and upselling strategies. - High per-customer revenue countries are ideal for acquisition-focused campaigns.\n\n\nHowever, the Customer table also contained a Country field. Differences between billing and customer country could reflect travel, gift purchases, or mismatched contact vs. billing addresses.\n\n\n\nsql\n\n-- Total Revenue by Country (Customer)\nSELECT \n    c.Country, \n    SUM(i.Total) AS TotalRevenue,\n    ROUND(SUM(i.Total)*100.0 / (SELECT SUM(Total) from Invoice), 2) AS PercentGlobalRevenue,\n    COUNT(DISTINCT c.CustomerId) AS NumCustomers,\n    ROUND(SUM(i.Total) / COUNT(DISTINCT c.CustomerId), 2) AS RevenuePerCustomer\nFROM Customer c\nJOIN Invoice i on c.CustomerId == i.CustomerId\nGROUP BY c.Country\n-- Sort Revenue (Highest to Lowest)\nORDER BY TotalRevenue DESC;\n\n\n\nDisplaying records 1 - 10\n\n\n\n\n\n\n\n\n\nCountry\nTotalRevenue\nPercentGlobalRevenue\nNumCustomers\nRevenuePerCustomer\n\n\n\n\nUSA\n523.06\n22.46\n13\n40.24\n\n\nCanada\n303.96\n13.05\n8\n37.99\n\n\nFrance\n195.10\n8.38\n5\n39.02\n\n\nBrazil\n190.10\n8.16\n5\n38.02\n\n\nGermany\n156.48\n6.72\n4\n39.12\n\n\nUnited Kingdom\n112.86\n4.85\n3\n37.62\n\n\nCzech Republic\n90.24\n3.88\n2\n45.12\n\n\nPortugal\n77.24\n3.32\n2\n38.62\n\n\nIndia\n75.26\n3.23\n2\n37.63\n\n\nChile\n46.62\n2.00\n1\n46.62\n\n\n\n\n\nTo identify any countries with mismatched revenue attribution, the aggregated views were joined and compared.\n\n\n\nsql\n\n-- Rows with discrepancies in Revenue by Country\n-- (Billing vs Customer)\n\n-- Revenue by Invoice.BillingCountry\nWITH billing_country_revenue AS (\n    SELECT \n        BillingCountry AS Country,\n        SUM(Total) AS Revenue_Billing\n    FROM Invoice\n    GROUP BY BillingCountry\n),\n\n-- Revenue by Customer Country (joined from Invoice.Customer)\ncustomer_country_revenue AS (\n    SELECT \n        c.Country AS Country,\n        SUM(i.Total) AS Revenue_Customer\n    FROM Invoice i\n    JOIN Customer c ON i.CustomerId = c.CustomerId\n    GROUP BY c.Country\n)\n\n-- Join the aggregations into a single table (by Country)\nSELECT \n    COALESCE(b.Country, c.Country) AS Country,\n    b.Revenue_Billing,\n    c.Revenue_Customer\nFROM billing_country_revenue b\nFULL OUTER JOIN customer_country_revenue c\n    ON b.Country = c.Country\n-- Select only rows where revenue differs by country source\nWHERE\n  b.Revenue_Billing IS DISTINCT FROM c.Revenue_Customer\nORDER BY Country;\n\n\n\n0 records\n\n\nCountry\nRevenue_Billing\nRevenue_Customer\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\nBilling and customer country match exactly in this data set, indicating no divergence due to travel, gifting, or alternate addresses. This simplifies location-based analysis but may also reflect a limitation in the data set’s realism.\n\n\n\nVisualizations\nTotal revenue per country across the entire data set was visualized with a Choropeth plot.\n\nRPython\n\n\n\n\n\nr\n\n# SQL Queries\n## Yearly Breakdown\nres_yearly_df &lt;- DBI::dbGetQuery(\n  con_chinook, \n  \"SELECT \n    -- Get Country and Year for grouping\n    i.BillingCountry as Country, \n    YEAR(i.InvoiceDate) as Year,\n    -- Calculate Total Revenue\n    SUM(i.Total) AS TotalRevenue,\n    -- Calculate % of Total/Global Revenue\n    ROUND(SUM(i.Total)*100.0 / (SELECT SUM(Total) from Invoice), 2) AS PercentGlobalRevenue,\n    -- Get Number of Customers\n    COUNT(DISTINCT c.CustomerId) AS NumCustomers,\n    -- Calculate Revenue per Customer\n    ROUND(SUM(i.Total) / COUNT(DISTINCT c.CustomerId), 2) AS RevenuePerCustomer\nFROM Customer c\nJOIN Invoice i on c.CustomerId == i.CustomerId\nGROUP BY i.BillingCountry, Year\n-- Sort Revenue (Highest to Lowest)\nORDER BY Year, TotalRevenue DESC;\"\n)\n\n## Total (all years)\nres_agg_df &lt;- DBI::dbGetQuery(\n  con_chinook, \n  \"SELECT \n    -- Get Country for grouping\n    i.BillingCountry as Country,\n    -- Set 'Year' to 'All' for grouping\n    'All' AS Year,\n    -- Calculate Total Revenue\n    SUM(i.Total) AS TotalRevenue,\n    -- Calculate % of Total/Global Revenue\n    ROUND(SUM(i.Total)*100.0 / (SELECT SUM(Total) from Invoice), 2) AS PercentGlobalRevenue,\n    -- Get Number of Customers\n    COUNT(DISTINCT c.CustomerId) AS NumCustomers,\n    -- Calculate Revenue per Customer\n    ROUND(SUM(i.Total) / COUNT(DISTINCT c.CustomerId), 2) AS RevenuePerCustomer\nFROM Customer c\nJOIN Invoice i on c.CustomerId == i.CustomerId\nGROUP BY i.BillingCountry,\n-- Sort Revenue (Highest to Lowest)\nORDER BY Year, TotalRevenue DESC;\"\n)\n\n# Combine data frames in R\nres_df &lt;- dplyr::bind_rows(\n  res_agg_df,\n  res_yearly_df |&gt; dplyr::mutate(Year = as.character(Year))\n  ) |&gt;\n  dplyr::mutate(\n    ## Add ISO Country Codes\n    iso_alpha = countrycode::countrycode(\n      Country, \n      origin = 'country.name', \n      destination = 'iso3c'\n      ),\n    ## Format Hover Text (&lt;b&gt;Country:&lt;/b&gt;&lt;br&gt; $TotalRevenue.##\")\n    hover_text = paste0(\n      \"&lt;b&gt;\", Country, \":&lt;/b&gt;&lt;br&gt; $\",\n      formatC(TotalRevenue, format = 'f', big.mark =\",'\", digits = 2)\n      )\n    ) \n\n# Get vector of unique years (layers/traces) - order with \"All\" first.\nyears &lt;- c(\"All\", sort(unique(res_yearly_df$Year)))\n\n# Get minimum and maximum values for TotalRevenue (Colorbar consistency)\nz_min_val &lt;- min(res_df$TotalRevenue, na.rm = TRUE)\nz_max_val &lt;- max(res_df$TotalRevenue, na.rm = TRUE)\n\n# Generate plotly Choropleth\nfig &lt;- plotly::plot_ly(\n  data = res_df,\n  type = 'choropleth',\n  locations = ~iso_alpha,\n  z = ~TotalRevenue,\n  # Set hover text to only display our desired, formatted output\n  text = ~hover_text,\n  hoverinfo = \"text\",\n  frame = ~Year,\n  # Set minimum and maximum TotalRevenue values, for consistent scale\n  zmin = z_min_val,\n  zmax = z_max_val,\n  # Title Colorbar/Legend\n  colorbar = list(\n    title = \"Total Revenue (USD$)\"\n  ),\n  # Color-blind friendly color scale\n  colorscale = \"Viridis\",\n  reversescale = TRUE,\n  showscale = TRUE,\n  # Give national boundaries a dark gray outline\n  marker = list(line = list(color = \"darkgrey\", width = 0.5))\n)\n\n# Layout with animation controls\nfig &lt;- fig %&gt;%\n  plotly::layout(\n    title = list(\n      text = \"Total Revenue by Country &lt;br&gt; 2009-01-01 to 2013-12-22\",\n      x = 0.5,\n      xanchor = \"center\",\n      font = list(size = 18)\n    ),\n    geo = list(\n      # Add a neat little frame around the world\n      showframe = TRUE, \n      # Add coast lines - ensures countries that aren't in data are seen\n      showcoastlines = TRUE, \n      # Use natural earth projection\n      projection = list(type = 'natural earth')\n      ),\n    updatemenus = list(\n      list(\n        type = \"dropdown\",\n        showactive = TRUE,\n        buttons = purrr::map(years, function(yr) {\n          list(\n            method = \"animate\",\n            args = list(list(yr), list(mode = \"immediate\", frame = list(duration = 0, redraw = TRUE))),\n            label = yr\n          )\n        }),\n        # Positioning of dropdown menu\n        x = 0.1,\n        y = 1.15,\n        xanchor = \"left\",\n        yanchor = \"top\"\n      )\n    ),\n    margin = list(t = 80)\n  ) %&gt;%\n  plotly::animation_opts(frame = 1000, transition = 0, redraw = TRUE)\n\n# Display interactive plot\nfig\n\n\n\n\n\n\n\n\n\n\n\npython\n\n# SQL Queries\n## Yearly Breakdown\nres_yearly_df = con_chinook.execute(\n    \"\"\"SELECT \n      -- Get Country and Year for grouping\n      i.BillingCountry as Country, \n      YEAR(i.InvoiceDate) as Year,\n      -- Calculate Total Revenue\n      SUM(i.Total) AS TotalRevenue,\n      -- Calculate % of Total/Global Revenue\n      ROUND(SUM(i.Total)*100.0 / (SELECT SUM(Total) from Invoice), 2) AS PercentGlobalRevenue,\n      -- Get Number of Customers\n      COUNT(DISTINCT c.CustomerId) AS NumCustomers,\n      -- Calculate Revenue per Customer\n      ROUND(SUM(i.Total) / COUNT(DISTINCT c.CustomerId), 2) AS RevenuePerCustomer\n  FROM Customer c\n  JOIN Invoice i on c.CustomerId == i.CustomerId\n  GROUP BY i.BillingCountry, Year\n  -- Sort Revenue (Highest to Lowest)\n  ORDER BY Year, TotalRevenue DESC;\"\"\"\n  ).df()\n\n## Total (all years)\nres_agg_df = con_chinook.execute(\n    \"\"\"SELECT \n      -- Get Country for grouping\n      i.BillingCountry as Country,\n      -- Set 'Year' to 'All' for grouping\n      'All' AS Year,\n      -- Calculate Total Revenue\n      SUM(i.Total) AS TotalRevenue,\n      -- Calculate % of Total/Global Revenue\n      ROUND(SUM(i.Total)*100.0 / (SELECT SUM(Total) from Invoice), 2) AS PercentGlobalRevenue,\n      -- Get Number of Customers\n      COUNT(DISTINCT c.CustomerId) AS NumCustomers,\n      -- Calculate Revenue per Customer\n      ROUND(SUM(i.Total) / COUNT(DISTINCT c.CustomerId), 2) AS RevenuePerCustomer\n  FROM Customer c\n  JOIN Invoice i on c.CustomerId == i.CustomerId\n  GROUP BY i.BillingCountry,\n  -- Sort Revenue (Highest to Lowest)\n  ORDER BY Year, TotalRevenue DESC;\"\"\"\n  ).df()\n\n# Combine data frames and ensure consistent types\nres_df = pd.concat([\n  res_agg_df,\n  res_yearly_df.assign(Year=res_yearly_df['Year'].astype(str))\n  ], ignore_index=True)\n\n# Add ISO Country Codes\ndef get_iso_alpha3(country_name):\n try:\n   return pycountry.countries.lookup(country_name).alpha_3\n except LookupError:\n   return None\n \nres_df['iso_alpha'] = res_df['Country'].apply(get_iso_alpha3)\n\n# Specify hover text\nres_df['hover_text'] = res_df.apply( \\\n  lambda row: f\"&lt;b&gt;{row['Country']}&lt;/b&gt;&lt;br&gt; ${row['TotalRevenue']:.2f}\", axis = 1 \\\n  )\n\n# Get unique years (layers/traces) - order with \"All\" first.\nyears = [\"All\"] + sorted(res_df[res_df['Year'] != 'All']['Year'].unique().tolist())\n\n# Get maximum and minimum TotalRevenue values (consistent scale)\nz_min_val = res_df['TotalRevenue'].min()\nz_max_val = res_df['TotalRevenue'].max()\n\n# Create traces\ntraces = []\n\n## One trace per year, with aggregate (\"All\") as the initial/default\nfor i,year in enumerate(years):\n  df_year = res_df[res_df['Year'] == year]\n  \n  trace = go.Choropleth(\n    locations = df_year['iso_alpha'],\n    z = df_year['TotalRevenue'],\n    zmin = z_min_val,\n    zmax = z_max_val,\n    text = df_year['hover_text'],\n    hoverinfo = 'text',\n    # Color-blind friendly color scale (reversed: darker with higher revenues)\n    colorscale = 'Viridis_r',\n    # Give national boundaries a dark grey outline\n    marker = dict(line=dict(color='darkgrey', width=0.5)),\n    # Title Colorbar/Legend\n    colorbar = dict(title='Total Revenue (USD$)'),\n    # Set aggregate (year == 'All') to default for visibility\n    visible = True if year == 'All' else False,\n    name = year\n  )\n  \n  traces.append(trace)\n\n# Create buttons for dropdown menu to select visible year\nbuttons = []\n\nfor i, year in enumerate(years):\n  visibility = [j == i for j in range(len(years))]\n  \n  buttons.append(dict(\n    label = year,\n    method = 'update',\n    args = [{'visible':visibility}]\n  ))\n\n# Generate plotly Choropleth\nfig = go.Figure(data=traces)\n\n# Format Layout with Dropdown\nfig.update_layout(\n  title = dict(\n    text = \"Total Revenue by Country &lt;br&gt; 2009-01-01 to 2013-12-22\",\n    x = 0.5,  # Center the title\n    xanchor = 'center',\n    font = dict(size=18)\n  ),\n  # Frame and view\n  geo = dict(\n    # Show countries and boundaries\n    showcountries = True,\n    # Give national boundaries a dark gray outline\n    countrycolor=\"darkgrey\",\n    # Add coast lines - ensure scountries that aren't in data are seen\n    showcoastlines = True,\n    coastlinecolor = \"gray\",\n    #  Ad a neat little frame around the world\n    showframe = True,\n    framecolor = \"black\",\n    # Use natural earth projection\n    projection_type = \"natural earth\"\n  ),\n  updatemenus = [dict(\n        # First button active by default (yr == \"All\")\n        active = 0,\n        buttons = buttons,\n        # Positioning of dropdown menu\n        x = 0.15,\n        y = 2,\n        xanchor = \"left\",\n        yanchor = \"top\"\n      )]\n    );\n\n# Display interactive plot\nfig.show()"
  },
  {
    "objectID": "projects/draft.html#question-2-what-genres-or-artists-generate-the-most-income",
    "href": "projects/draft.html#question-2-what-genres-or-artists-generate-the-most-income",
    "title": "R & SQL-Driven Business Intelligence Dashboard (Chinook ‘Digital Music Store’)",
    "section": "Question 2: What genres or artists generate the most income?",
    "text": "Question 2: What genres or artists generate the most income?\n\nKey Tables: InvoiceLine, Track, Artist, Genre\nExplanation: InvoiceLine provides data relating to individual unit sales. Links between Track, Artist, and Genre provide additional details, such as artist name and genre, characterizing these unit sales."
  },
  {
    "objectID": "projects/draft.html#question-3-how-many-customers-are-repeat-buyers",
    "href": "projects/draft.html#question-3-how-many-customers-are-repeat-buyers",
    "title": "R & SQL-Driven Business Intelligence Dashboard (Chinook ‘Digital Music Store’)",
    "section": "Question 3: How many customers are repeat buyers?",
    "text": "Question 3: How many customers are repeat buyers?\n\nKey Tables: Invoice, Customer, InvoiceLine\nExplanation: Customer provides key customer data. Links to Invoice provide sales frequency information linked to each Customer, which may be further broken down to individual units or cost-per-unit with links to InvoiceLine."
  },
  {
    "objectID": "projects/draft.html#question-4.-how-do-sales-trends-evolve-over-time",
    "href": "projects/draft.html#question-4.-how-do-sales-trends-evolve-over-time",
    "title": "R & SQL-Driven Business Intelligence Dashboard (Chinook ‘Digital Music Store’)",
    "section": "Question 4. How do sales trends evolve over time?",
    "text": "Question 4. How do sales trends evolve over time?\n\nKey Tables: Invoice, InvoiceLine, Customer\nExplanation: Invoice provides sales data, including date of sale and revenue. This data may be further broken down to individual units or cost-per-unit with links to InvoiceLine. Further characterization may be done with links to Customer or other tables linked to InvoiceLine."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Welcome! Here you’ll find a small collection of personal projects that reflect some of my skills, interests, and growth. Feel free to explore — use the filters to browse by category and dive into the areas that interest you the most.\n\n\n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nR & SQL-Driven Business Intelligence Dashboard (Chinook ‘Digital Music Store’)\n\n\n\n\n\n\n\nR\n\n\nSQL\n\n\nDashboards\n\n\nAnalysis\n\n\nBusiness Intelligence\n\n\n\n\nThis project explores the Chinook dataset — a mock digital music store — to uncover key business insights around revenue, customers, and performance. It combines SQL analysis with dashboard development to present findings visually.\n\n\n\n\n\n\nJun 26, 2025\n\n\nMorrigan M.\n\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n Back to top"
  }
]